{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mModule model_selection has been ported to Julia - try `import ScikitLearn: CrossValidation` instead\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ ScikitLearn.Skcore C:\\Users\\jaydh\\.julia\\packages\\ScikitLearn\\Wvn7B\\src\\Skcore.jl:240\u001b[39m\n",
      "WARNING: redefinition of constant train_test_split. This may fail, cause incorrect answers, or produce other errors.\n",
      "WARNING: redefinition of constant SVC. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <class 'sklearn.svm._classes.SVC'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LIBSVM\n",
    "using RDatasets\n",
    "using Printf\n",
    "using Statistics\n",
    "using Random\n",
    "using Plots\n",
    "using GLM\n",
    "using StatsBase\n",
    "using ScikitLearn\n",
    "using ScikitLearn.GridSearch: RandomizedSearchCV\n",
    "using JLD2\n",
    "using PyCall\n",
    "using CSV\n",
    "stats = pyimport(\"scipy.stats\")\n",
    "imblearn = pyimport(\"imblearn\")\n",
    "@sk_import model_selection: train_test_split\n",
    "\n",
    "@sk_import svm: SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repeat_svm (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_svm(df)\n",
    "    X = Matrix(df[:,4:end]);\n",
    "    y = df.labels\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.3); # train-test split\n",
    "\n",
    "    sampler(a, b) = stats.loguniform(a, b) # samples from range (a,b) according to log uniform distribution \n",
    "\n",
    "    # specify parameters and distributions to sample from\n",
    "    param_dist = Dict(\"svc__C\" => sampler(1e-6, 1000.0),\n",
    "    \"svc__gamma\" => sampler(1e-6, 1000.0))\n",
    "\n",
    "    # use SMOTE object to randomly oversample training set\n",
    "    sm = imblearn.over_sampling.SMOTE(random_state=42)\n",
    "\n",
    "    # SVM classifier\n",
    "    clf = SVC()\n",
    "\n",
    "    # add oversampling and SVM to pipeline to only oversample training set during CV\n",
    "    svm_pipeline =  imblearn.pipeline.make_pipeline(sm,clf)\n",
    "\n",
    "    # hyperparameter tuning via random search, refit to best model\n",
    "    n_iter_search = 100\n",
    "    random_search = RandomizedSearchCV(svm_pipeline,\n",
    "                                       param_dist,\n",
    "                                       n_iter=n_iter_search,\n",
    "                                       random_state=MersenneTwister(41),\n",
    "                                       refit=true)\n",
    "\n",
    "    \n",
    "    ScikitLearn.fit!(random_search, Xtrain, ytrain)\n",
    "\n",
    "    # get optimal hyperparameters\n",
    "    best = random_search.best_params_\n",
    "    C = get(best, :svc__C, \"Error\")\n",
    "    G = get(best, :svc__gamma, \"Error\")\n",
    "\n",
    "    score = ScikitLearn.score(random_search, Xtest, ytest)\n",
    "\n",
    "    return [score,C,G]\n",
    "\n",
    "end\n",
    "\n",
    "function repeat_svm(df,c,g,n_repeats)\n",
    "    accuracies=[]\n",
    "    for i=1:n_repeats\n",
    "        df=df[shuffle(1:nrow(df)),:];\n",
    "        X = Matrix(df[:,4:end]);\n",
    "        y = df.labels\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=0.3); # train-test split\n",
    "        clf = SVC(C=c,gamma=g)\n",
    "        sm = imblearn.over_sampling.SMOTE(random_state=41)\n",
    "\n",
    "        svm_pipeline =  imblearn.pipeline.make_pipeline(sm,clf)\n",
    "\n",
    "        svm_pipeline.fit(Xtrain,ytrain)\n",
    "\n",
    "        ypredict = svm_pipeline.predict(Xtest)\n",
    "\n",
    "        acc = mean(ypredict .== ytest) * 100\n",
    "\n",
    "        # uncomment to check that both classes are being predicted\n",
    "        #println(\"\\nypredict:\", countmap(ypredict))\n",
    "        #println(\"ytest:\", countmap(ytest),\"\\n\")\n",
    "\n",
    "        append!(accuracies,acc)\n",
    "    end\n",
    "    return accuracies\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "populatePHdata (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function populatePHdata(imagepath, size)\n",
    "    df = DataFrame(ids=Int64[],times=Int64[],labels=[])\n",
    "    for i in 1:size\n",
    "        colname = string(\"feature_\",i)\n",
    "        df[!,colname] = Float64[]\n",
    "    end\n",
    "    for i in 1:972\n",
    "        id = simulation_df[i,\"id\"]\n",
    "        time = simulation_df[i,\"time\"]\n",
    "        label = simulation_df[i,\"label\"]\n",
    "        imagename = string(id)*\"_\"*string(time)*\"_img.jld2\"\n",
    "        V = load_object(imagepath*imagename)\n",
    "        row = Any[]\n",
    "        append!(row,id)\n",
    "        append!(row,time)\n",
    "        append!(row,label)\n",
    "        for x in V\n",
    "            append!(row,x)\n",
    "        end\n",
    "        push!(df,row)\n",
    "    end\n",
    "    return df\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVM_accuracies (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function SVM_accuracies(df)\n",
    "    X = Matrix(df[:,4:end])\n",
    "\n",
    "    dt = fit(UnitRangeTransform, X; dims=1, unit=true)\n",
    "\n",
    "    Xn = StatsBase.transform(dt,X)\n",
    "    for i in 1:size(X)[1]\n",
    "        df[i,:][4:end] = Xn[i,:]\n",
    "    end\n",
    "\n",
    "    a, C, G = train_svm(df)\n",
    "    accuracies = repeat_svm(df,C,G,10)\n",
    "    return accuracies\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_df = CSV.read(\"labels.csv\", DataFrame);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vr_tumour_h0 = populatePHdata(\"persistence_images\\\\vr\\\\tumour_h0\\\\\",20);\n",
    "\n",
    "accuracies = SVM_accuracies(df_vr_tumour_h0);\n",
    "\n",
    "#CSV.write(\"vr_tumour_h0_accuracies.csv\", DataFrame(vector=accuracies));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vr_tumour_h1 = populatePHdata(\"persistence_images\\\\vr\\\\tumour_h1\\\\\",400);\n",
    "\n",
    "accuracies = SVM_accuracies(df_vr_tumour_h1);\n",
    "\n",
    "#CSV.write(\"vr_tumour_h1_accuracies.csv\", DataFrame(vector=accuracies));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vr_macrophage_h0 = populatePHdata(\"persistence_images\\\\vr\\\\macrophages_h0\\\\\",20);\n",
    "\n",
    "accuracies = SVM_accuracies(df_vr_macrophage_h0);\n",
    "\n",
    "#CSV.write(\"vr_macrophage_h0_accuracies.csv\", DataFrame(vector=accuracies));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vr_macrophage_h1 = populatePHdata(\"persistence_images\\\\vr\\\\macrophages_h1\\\\\",400);\n",
    "\n",
    "accuracies = SVM_accuracies(df_vr_macrophage_h1);\n",
    "\n",
    "#CSV.write(\"vr_macrophage_h1_accuracies.csv\", DataFrame(vector=accuracies));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dowker_mt_h0 = populatePHdata(\"persistence_images\\\\dowker\\\\macrophage_tumour_h0\\\\\",400);\n",
    "\n",
    "accuracies = SVM_accuracies(df_dowker_mt_h0);\n",
    "\n",
    "#CSV.write(\"dowker_mt_h0_accuracies.csv\", DataFrame(vector=accuracies));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dowker_mt_h1 = populatePHdata(\"persistence_images\\\\dowker\\\\macrophage_tumour_h1\\\\\",400);\n",
    "\n",
    "accuracies = SVM_accuracies(df_dowker_mt_h1);\n",
    "\n",
    "#CSV.write(\"dowker_mt_h1_accuracies.csv\", DataFrame(vector=accuracies));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dowker_mv_h0 = populatePHdata(\"persistence_images\\\\dowker\\\\macrophage_vessel_h0\\\\\",400);\n",
    "\n",
    "accuracies = SVM_accuracies(df_dowker_mv_h0);\n",
    "\n",
    "#CSV.write(\"dowker_mv_h0_accuracies.csv\", DataFrame(vector=accuracies));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dowker_mv_h1 = populatePHdata(\"persistence_images\\\\dowker\\\\macrophage_vessel_h1\\\\\",400);\n",
    "\n",
    "accuracies = SVM_accuracies(df_dowker_mv_h1);\n",
    "\n",
    "#CSV.write(\"dowker_mv_h1_accuracies.csv\", DataFrame(vector=accuracies));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dowker_tv_h0 = populatePHdata(\"persistence_images\\\\dowker\\\\tumour_vessel_h0\\\\\",400);\n",
    "\n",
    "accuracies = SVM_accuracies(df_dowker_tv_h0);\n",
    "\n",
    "#CSV.write(\"dowker_tv_h0_accuracies.csv\", DataFrame(vector=accuracies));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dowker_tv_h1 = populatePHdata(\"persistence_images\\\\dowker\\\\tumour_vessel_h1\\\\\",400);\n",
    "\n",
    "accuracies = SVM_accuracies(df_dowker_tv_h1);\n",
    "\n",
    "#CSV.write(\"dowker_tv_h1_accuracies.csv\", DataFrame(vector=accuracies));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_top_df = CSV.read(\"non_toological_data.csv\", DataFrame);\n",
    "\n",
    "for col in names(non_top_df[:,4:end])\n",
    "    if (typeof(non_top_df[!,col][1]) == Int64)\n",
    "        non_top_df[!,col] = Float64.(non_top_df[!,col])\n",
    "    end\n",
    "end\n",
    "\n",
    "accuracies = SVM_accuracies(non_top_df);\n",
    "\n",
    "#CSV.write(\"simple_accuracy.csv\", DataFrame(vector=accuracies));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
