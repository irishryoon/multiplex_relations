{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module ext.\n",
      "┌ Warning: Module model_selection has been ported to Julia - try `import ScikitLearn: CrossValidation` instead\n",
      "└ @ ScikitLearn.Skcore C:\\Users\\jaydh\\.julia\\packages\\ScikitLearn\\ssekP\\src\\Skcore.jl:179\n",
      "WARNING: redefinition of constant train_test_split. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <function train_test_split at 0x0000000097C318B0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"compute_ph2.jl\")\n",
    "using LIBSVM\n",
    "using RDatasets\n",
    "using Printf\n",
    "using Statistics\n",
    "using Random\n",
    "using .ext\n",
    "using Plots\n",
    "using GLM\n",
    "using StatsBase\n",
    "using ScikitLearn\n",
    "@sk_import model_selection: train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i = 1:10:1620]\n",
    "y = [j for j = 6000:10:7100]\n",
    "ids = vcat(x,y)\n",
    "times = [250,300,350,400,450,500]\n",
    "sims = [[id,time] for id in ids for time in times];\n",
    "celltype1 = \"Vessel\";\n",
    "celltype2 = \"Macrophage\";\n",
    "sims = cleanSimsDowker(sims,celltype1,celltype2);\n",
    "SIZE = 15;\n",
    "VAR = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188-element Vector{Vector{Int64}}:\n",
       " [1, 250]\n",
       " [1, 300]\n",
       " [1, 350]\n",
       " [1, 400]\n",
       " [1, 450]\n",
       " [1, 500]\n",
       " [11, 250]\n",
       " [11, 300]\n",
       " [11, 350]\n",
       " [11, 400]\n",
       " [11, 450]\n",
       " [11, 500]\n",
       " [21, 250]\n",
       " ⋮\n",
       " [7080, 250]\n",
       " [7080, 300]\n",
       " [7080, 350]\n",
       " [7080, 400]\n",
       " [7080, 450]\n",
       " [7080, 500]\n",
       " [7090, 250]\n",
       " [7090, 300]\n",
       " [7090, 350]\n",
       " [7090, 400]\n",
       " [7090, 450]\n",
       " [7090, 500]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = getBinaryLabels(sims);\n",
    " # gets labels for each sim. \n",
    " # 1 if M2/(M1+M2) > 0.5. \n",
    " # 0 Otherwise. \n",
    " # Thresholding phenotypes < 0.5 anti-tumour, >= 0.5 pro-tumour\n",
    "features = getDowkerfeatures(0, sims, celltype1, celltype2, SIZE, VAR);\n",
    " # gets feature vectors for chosen method. Outputs matrix of size N x M \n",
    " # N = number of sims\n",
    " # M = size of feature vector, i.e. M = SIZE*SIZE where SIZE = size of persistence image\n",
    " # e.g. 1188 sims considered, calculate 20x20 persistence images for each --> 1188x400 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(sims = sims, labels = labels)\n",
    "for i = 1:(SIZE*SIZE)\n",
    "    colname = string(\"feature_\",i)\n",
    "    df[!,colname] = features[:,i]\n",
    "end\n",
    "# create dataframe with simulations, labels, and all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sims</th><th>labels</th><th>feature_1</th><th>feature_2</th><th>feature_3</th><th>feature_4</th><th>feature_5</th><th>feature_6</th></tr><tr><th></th><th>Array…</th><th>Any</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>1,188 rows × 227 columns (omitted printing of 219 columns)</p><tr><th>1</th><td>[1, 250]</td><td>0</td><td>0.00740886</td><td>0.020425</td><td>0.040385</td><td>0.0859821</td><td>0.101502</td><td>0.0544513</td></tr><tr><th>2</th><td>[1, 300]</td><td>0</td><td>0.0174308</td><td>0.0376076</td><td>0.0687476</td><td>0.0985676</td><td>0.0817153</td><td>0.0403405</td></tr><tr><th>3</th><td>[1, 350]</td><td>0</td><td>0.0157873</td><td>0.0467754</td><td>0.0830455</td><td>0.0968372</td><td>0.0567234</td><td>0.0225275</td></tr><tr><th>4</th><td>[1, 400]</td><td>0</td><td>0.0226509</td><td>0.0499479</td><td>0.0740949</td><td>0.0785724</td><td>0.0438015</td><td>0.0223333</td></tr><tr><th>5</th><td>[1, 450]</td><td>0</td><td>0.0301554</td><td>0.0786518</td><td>0.109992</td><td>0.0793434</td><td>0.0365893</td><td>0.0148492</td></tr><tr><th>6</th><td>[1, 500]</td><td>0</td><td>0.035206</td><td>0.0791842</td><td>0.100837</td><td>0.0794835</td><td>0.0382706</td><td>0.00944709</td></tr><tr><th>7</th><td>[11, 250]</td><td>0</td><td>0.013138</td><td>0.0357185</td><td>0.0585445</td><td>0.0917087</td><td>0.096745</td><td>0.0623645</td></tr><tr><th>8</th><td>[11, 300]</td><td>0</td><td>0.0190491</td><td>0.0386717</td><td>0.060178</td><td>0.0828999</td><td>0.0776181</td><td>0.0457038</td></tr><tr><th>9</th><td>[11, 350]</td><td>0</td><td>0.0236567</td><td>0.0532344</td><td>0.0775518</td><td>0.0899351</td><td>0.0629278</td><td>0.0188073</td></tr><tr><th>10</th><td>[11, 400]</td><td>0</td><td>0.0229197</td><td>0.0591023</td><td>0.0983957</td><td>0.102367</td><td>0.0548678</td><td>0.0112351</td></tr><tr><th>11</th><td>[11, 450]</td><td>0</td><td>0.0293304</td><td>0.070972</td><td>0.0999982</td><td>0.0934099</td><td>0.0558732</td><td>0.0184393</td></tr><tr><th>12</th><td>[11, 500]</td><td>0</td><td>0.034963</td><td>0.0720964</td><td>0.101294</td><td>0.0861154</td><td>0.0348707</td><td>0.00749606</td></tr><tr><th>13</th><td>[21, 250]</td><td>0</td><td>0.00356349</td><td>0.00952977</td><td>0.021136</td><td>0.04983</td><td>0.0700417</td><td>0.0682291</td></tr><tr><th>14</th><td>[21, 300]</td><td>0</td><td>0.00905973</td><td>0.0364692</td><td>0.0742886</td><td>0.103064</td><td>0.101021</td><td>0.0719881</td></tr><tr><th>15</th><td>[21, 350]</td><td>0</td><td>0.0129946</td><td>0.0399851</td><td>0.0797128</td><td>0.100698</td><td>0.0771767</td><td>0.0313962</td></tr><tr><th>16</th><td>[21, 400]</td><td>0</td><td>0.0198415</td><td>0.04827</td><td>0.0900911</td><td>0.109381</td><td>0.073885</td><td>0.0237074</td></tr><tr><th>17</th><td>[21, 450]</td><td>0</td><td>0.0254568</td><td>0.0599276</td><td>0.0853166</td><td>0.0884532</td><td>0.054004</td><td>0.0123563</td></tr><tr><th>18</th><td>[21, 500]</td><td>0</td><td>0.0290181</td><td>0.0726347</td><td>0.106129</td><td>0.087372</td><td>0.0358052</td><td>0.00544947</td></tr><tr><th>19</th><td>[31, 250]</td><td>0</td><td>0.00612547</td><td>0.0167578</td><td>0.0367771</td><td>0.0545762</td><td>0.0571235</td><td>0.0372883</td></tr><tr><th>20</th><td>[31, 300]</td><td>0</td><td>0.00969114</td><td>0.0275658</td><td>0.057945</td><td>0.0846462</td><td>0.0994275</td><td>0.0733412</td></tr><tr><th>21</th><td>[31, 350]</td><td>0</td><td>0.0159672</td><td>0.0404165</td><td>0.0639703</td><td>0.0853355</td><td>0.0918413</td><td>0.0574773</td></tr><tr><th>22</th><td>[31, 400]</td><td>0</td><td>0.0217988</td><td>0.0482372</td><td>0.0544521</td><td>0.0560687</td><td>0.0640278</td><td>0.0406063</td></tr><tr><th>23</th><td>[31, 450]</td><td>0</td><td>0.0231163</td><td>0.0598474</td><td>0.0737603</td><td>0.0759943</td><td>0.0705075</td><td>0.0306437</td></tr><tr><th>24</th><td>[31, 500]</td><td>0</td><td>0.0246164</td><td>0.0606624</td><td>0.0905866</td><td>0.0931641</td><td>0.0537345</td><td>0.0107984</td></tr><tr><th>25</th><td>[41, 250]</td><td>0</td><td>0.00434692</td><td>0.0138772</td><td>0.0248282</td><td>0.052296</td><td>0.0658451</td><td>0.043403</td></tr><tr><th>26</th><td>[41, 300]</td><td>0</td><td>0.0140771</td><td>0.0400341</td><td>0.0649237</td><td>0.0884237</td><td>0.0827629</td><td>0.0542387</td></tr><tr><th>27</th><td>[41, 350]</td><td>0</td><td>0.0229581</td><td>0.0511636</td><td>0.0710792</td><td>0.0913629</td><td>0.0921482</td><td>0.0538319</td></tr><tr><th>28</th><td>[41, 400]</td><td>0</td><td>0.0280204</td><td>0.0608061</td><td>0.0708631</td><td>0.0617828</td><td>0.0372325</td><td>0.0233666</td></tr><tr><th>29</th><td>[41, 450]</td><td>0</td><td>0.0227122</td><td>0.0521964</td><td>0.0827552</td><td>0.0816456</td><td>0.049577</td><td>0.0258006</td></tr><tr><th>30</th><td>[41, 500]</td><td>0</td><td>0.0276887</td><td>0.0577667</td><td>0.0913835</td><td>0.0894534</td><td>0.0471727</td><td>0.018509</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& sims & labels & feature\\_1 & feature\\_2 & feature\\_3 & feature\\_4 & feature\\_5 & feature\\_6 & \\\\\n",
       "\t\\hline\n",
       "\t& Array… & Any & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & [1, 250] & 0 & 0.00740886 & 0.020425 & 0.040385 & 0.0859821 & 0.101502 & 0.0544513 & $\\dots$ \\\\\n",
       "\t2 & [1, 300] & 0 & 0.0174308 & 0.0376076 & 0.0687476 & 0.0985676 & 0.0817153 & 0.0403405 & $\\dots$ \\\\\n",
       "\t3 & [1, 350] & 0 & 0.0157873 & 0.0467754 & 0.0830455 & 0.0968372 & 0.0567234 & 0.0225275 & $\\dots$ \\\\\n",
       "\t4 & [1, 400] & 0 & 0.0226509 & 0.0499479 & 0.0740949 & 0.0785724 & 0.0438015 & 0.0223333 & $\\dots$ \\\\\n",
       "\t5 & [1, 450] & 0 & 0.0301554 & 0.0786518 & 0.109992 & 0.0793434 & 0.0365893 & 0.0148492 & $\\dots$ \\\\\n",
       "\t6 & [1, 500] & 0 & 0.035206 & 0.0791842 & 0.100837 & 0.0794835 & 0.0382706 & 0.00944709 & $\\dots$ \\\\\n",
       "\t7 & [11, 250] & 0 & 0.013138 & 0.0357185 & 0.0585445 & 0.0917087 & 0.096745 & 0.0623645 & $\\dots$ \\\\\n",
       "\t8 & [11, 300] & 0 & 0.0190491 & 0.0386717 & 0.060178 & 0.0828999 & 0.0776181 & 0.0457038 & $\\dots$ \\\\\n",
       "\t9 & [11, 350] & 0 & 0.0236567 & 0.0532344 & 0.0775518 & 0.0899351 & 0.0629278 & 0.0188073 & $\\dots$ \\\\\n",
       "\t10 & [11, 400] & 0 & 0.0229197 & 0.0591023 & 0.0983957 & 0.102367 & 0.0548678 & 0.0112351 & $\\dots$ \\\\\n",
       "\t11 & [11, 450] & 0 & 0.0293304 & 0.070972 & 0.0999982 & 0.0934099 & 0.0558732 & 0.0184393 & $\\dots$ \\\\\n",
       "\t12 & [11, 500] & 0 & 0.034963 & 0.0720964 & 0.101294 & 0.0861154 & 0.0348707 & 0.00749606 & $\\dots$ \\\\\n",
       "\t13 & [21, 250] & 0 & 0.00356349 & 0.00952977 & 0.021136 & 0.04983 & 0.0700417 & 0.0682291 & $\\dots$ \\\\\n",
       "\t14 & [21, 300] & 0 & 0.00905973 & 0.0364692 & 0.0742886 & 0.103064 & 0.101021 & 0.0719881 & $\\dots$ \\\\\n",
       "\t15 & [21, 350] & 0 & 0.0129946 & 0.0399851 & 0.0797128 & 0.100698 & 0.0771767 & 0.0313962 & $\\dots$ \\\\\n",
       "\t16 & [21, 400] & 0 & 0.0198415 & 0.04827 & 0.0900911 & 0.109381 & 0.073885 & 0.0237074 & $\\dots$ \\\\\n",
       "\t17 & [21, 450] & 0 & 0.0254568 & 0.0599276 & 0.0853166 & 0.0884532 & 0.054004 & 0.0123563 & $\\dots$ \\\\\n",
       "\t18 & [21, 500] & 0 & 0.0290181 & 0.0726347 & 0.106129 & 0.087372 & 0.0358052 & 0.00544947 & $\\dots$ \\\\\n",
       "\t19 & [31, 250] & 0 & 0.00612547 & 0.0167578 & 0.0367771 & 0.0545762 & 0.0571235 & 0.0372883 & $\\dots$ \\\\\n",
       "\t20 & [31, 300] & 0 & 0.00969114 & 0.0275658 & 0.057945 & 0.0846462 & 0.0994275 & 0.0733412 & $\\dots$ \\\\\n",
       "\t21 & [31, 350] & 0 & 0.0159672 & 0.0404165 & 0.0639703 & 0.0853355 & 0.0918413 & 0.0574773 & $\\dots$ \\\\\n",
       "\t22 & [31, 400] & 0 & 0.0217988 & 0.0482372 & 0.0544521 & 0.0560687 & 0.0640278 & 0.0406063 & $\\dots$ \\\\\n",
       "\t23 & [31, 450] & 0 & 0.0231163 & 0.0598474 & 0.0737603 & 0.0759943 & 0.0705075 & 0.0306437 & $\\dots$ \\\\\n",
       "\t24 & [31, 500] & 0 & 0.0246164 & 0.0606624 & 0.0905866 & 0.0931641 & 0.0537345 & 0.0107984 & $\\dots$ \\\\\n",
       "\t25 & [41, 250] & 0 & 0.00434692 & 0.0138772 & 0.0248282 & 0.052296 & 0.0658451 & 0.043403 & $\\dots$ \\\\\n",
       "\t26 & [41, 300] & 0 & 0.0140771 & 0.0400341 & 0.0649237 & 0.0884237 & 0.0827629 & 0.0542387 & $\\dots$ \\\\\n",
       "\t27 & [41, 350] & 0 & 0.0229581 & 0.0511636 & 0.0710792 & 0.0913629 & 0.0921482 & 0.0538319 & $\\dots$ \\\\\n",
       "\t28 & [41, 400] & 0 & 0.0280204 & 0.0608061 & 0.0708631 & 0.0617828 & 0.0372325 & 0.0233666 & $\\dots$ \\\\\n",
       "\t29 & [41, 450] & 0 & 0.0227122 & 0.0521964 & 0.0827552 & 0.0816456 & 0.049577 & 0.0258006 & $\\dots$ \\\\\n",
       "\t30 & [41, 500] & 0 & 0.0276887 & 0.0577667 & 0.0913835 & 0.0894534 & 0.0471727 & 0.018509 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1188×227 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m sims        \u001b[0m\u001b[1m labels \u001b[0m\u001b[1m feature_1   \u001b[0m\u001b[1m feature_2   \u001b[0m\u001b[1m feature_3   \u001b[0m\u001b[1m feature_4 \u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Array…      \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64   \u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │ [1, 250]     0       0.00740886   0.020425     0.040385     0.0859821  ⋯\n",
       "    2 │ [1, 300]     0       0.0174308    0.0376076    0.0687476    0.0985676\n",
       "    3 │ [1, 350]     0       0.0157873    0.0467754    0.0830455    0.0968372\n",
       "    4 │ [1, 400]     0       0.0226509    0.0499479    0.0740949    0.0785724\n",
       "    5 │ [1, 450]     0       0.0301554    0.0786518    0.109992     0.0793434  ⋯\n",
       "    6 │ [1, 500]     0       0.035206     0.0791842    0.100837     0.0794835\n",
       "    7 │ [11, 250]    0       0.013138     0.0357185    0.0585445    0.0917087\n",
       "    8 │ [11, 300]    0       0.0190491    0.0386717    0.060178     0.0828999\n",
       "    9 │ [11, 350]    0       0.0236567    0.0532344    0.0775518    0.0899351  ⋯\n",
       "   10 │ [11, 400]    0       0.0229197    0.0591023    0.0983957    0.102367\n",
       "   11 │ [11, 450]    0       0.0293304    0.070972     0.0999982    0.0934099\n",
       "  ⋮   │      ⋮         ⋮          ⋮            ⋮            ⋮            ⋮     ⋱\n",
       " 1179 │ [7080, 350]  0       0.0100953    0.0207222    0.0238724    0.0366272\n",
       " 1180 │ [7080, 400]  0       0.0147885    0.0274916    0.0361643    0.0511132  ⋯\n",
       " 1181 │ [7080, 450]  0       0.0151339    0.0317834    0.0525218    0.0715828\n",
       " 1182 │ [7080, 500]  0       0.0189886    0.0304642    0.0449425    0.066176\n",
       " 1183 │ [7090, 250]  0       7.05139e-70  2.50722e-70  9.31187e-72  2.63838e-7\n",
       " 1184 │ [7090, 300]  0       0.0          0.0          0.0          0.0        ⋯\n",
       " 1185 │ [7090, 350]  0       3.30842e-30  2.74868e-30  4.19121e-31  5.41953e-3\n",
       " 1186 │ [7090, 400]  1       8.12647e-13  1.32092e-11  2.64448e-11  1.52194e-1\n",
       " 1187 │ [7090, 450]  1       3.29312e-6   2.66553e-5   7.76424e-5   6.45061e-5\n",
       " 1188 │ [7090, 500]  1       0.000598703  0.00281892   0.00286001   0.00102713 ⋯\n",
       "\u001b[36m                                               222 columns and 1167 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>sims</th><th>labels</th><th>feature_1</th><th>feature_2</th><th>feature_3</th><th>feature_4</th><th>feature_5</th></tr><tr><th></th><th>Array…</th><th>Any</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>541 rows × 227 columns (omitted printing of 220 columns)</p><tr><th>1</th><td>[951, 500]</td><td>0</td><td>0.011055</td><td>0.0230288</td><td>0.0252146</td><td>0.0153139</td><td>0.0127972</td></tr><tr><th>2</th><td>[651, 450]</td><td>1</td><td>0.0145121</td><td>0.0130357</td><td>0.0150536</td><td>0.0291809</td><td>0.0265747</td></tr><tr><th>3</th><td>[901, 250]</td><td>0</td><td>1.98983e-9</td><td>7.00509e-7</td><td>0.00024704</td><td>0.00665223</td><td>0.0187105</td></tr><tr><th>4</th><td>[1371, 250]</td><td>1</td><td>5.55306e-24</td><td>2.45581e-23</td><td>2.4084e-23</td><td>5.05982e-24</td><td>9.5356e-26</td></tr><tr><th>5</th><td>[1151, 350]</td><td>1</td><td>0.00296121</td><td>0.00619825</td><td>0.0107698</td><td>0.00703784</td><td>0.000701231</td></tr><tr><th>6</th><td>[821, 400]</td><td>1</td><td>0.00421397</td><td>0.0187837</td><td>0.0296966</td><td>0.0199009</td><td>0.00742934</td></tr><tr><th>7</th><td>[6410, 450]</td><td>1</td><td>0.00125018</td><td>0.00613746</td><td>0.0113962</td><td>0.0179503</td><td>0.0253942</td></tr><tr><th>8</th><td>[1151, 450]</td><td>1</td><td>0.00616752</td><td>0.0121388</td><td>0.016132</td><td>0.0236991</td><td>0.0178399</td></tr><tr><th>9</th><td>[771, 450]</td><td>0</td><td>0.00141156</td><td>0.00124019</td><td>0.00550951</td><td>0.013438</td><td>0.0220592</td></tr><tr><th>10</th><td>[451, 500]</td><td>0</td><td>0.0101826</td><td>0.0232314</td><td>0.0313183</td><td>0.0272385</td><td>0.0300795</td></tr><tr><th>11</th><td>[461, 500]</td><td>0</td><td>0.0171828</td><td>0.0337653</td><td>0.0553214</td><td>0.0778543</td><td>0.0736219</td></tr><tr><th>12</th><td>[6730, 250]</td><td>0</td><td>3.73077e-6</td><td>0.000253219</td><td>0.00148327</td><td>0.00168478</td><td>0.000569692</td></tr><tr><th>13</th><td>[1351, 250]</td><td>0</td><td>8.77536e-48</td><td>5.89834e-47</td><td>7.19013e-47</td><td>2.22669e-47</td><td>6.8542e-49</td></tr><tr><th>14</th><td>[1381, 350]</td><td>1</td><td>0.00389989</td><td>0.00577678</td><td>0.0025902</td><td>0.000141016</td><td>5.97338e-7</td></tr><tr><th>15</th><td>[51, 500]</td><td>0</td><td>0.0278803</td><td>0.0619403</td><td>0.0836656</td><td>0.0915658</td><td>0.0577899</td></tr><tr><th>16</th><td>[6190, 400]</td><td>0</td><td>0.00809457</td><td>0.0244316</td><td>0.0366216</td><td>0.0323021</td><td>0.0308711</td></tr><tr><th>17</th><td>[1121, 350]</td><td>1</td><td>0.00639722</td><td>0.0165158</td><td>0.0313132</td><td>0.0329414</td><td>0.029612</td></tr><tr><th>18</th><td>[1191, 500]</td><td>1</td><td>0.012989</td><td>0.0236959</td><td>0.0249193</td><td>0.0202414</td><td>0.019648</td></tr><tr><th>19</th><td>[941, 350]</td><td>1</td><td>0.000827498</td><td>0.000323136</td><td>0.000655285</td><td>0.011354</td><td>0.0455154</td></tr><tr><th>20</th><td>[6580, 300]</td><td>0</td><td>0.000696665</td><td>0.00130676</td><td>0.00297553</td><td>0.00814676</td><td>0.0076814</td></tr><tr><th>21</th><td>[1191, 300]</td><td>0</td><td>4.78119e-9</td><td>9.15957e-7</td><td>1.37427e-5</td><td>2.61787e-5</td><td>1.43727e-5</td></tr><tr><th>22</th><td>[421, 250]</td><td>0</td><td>0.000429851</td><td>0.000964426</td><td>0.00346012</td><td>0.00414652</td><td>0.00182862</td></tr><tr><th>23</th><td>[611, 500]</td><td>0</td><td>0.00637551</td><td>0.0100621</td><td>0.00819</td><td>0.00440917</td><td>0.0203919</td></tr><tr><th>24</th><td>[621, 500]</td><td>1</td><td>0.0086813</td><td>0.0194345</td><td>0.0254169</td><td>0.0439718</td><td>0.0548299</td></tr><tr><th>25</th><td>[921, 400]</td><td>1</td><td>0.00369839</td><td>0.00704631</td><td>0.0116764</td><td>0.00892959</td><td>0.00133876</td></tr><tr><th>26</th><td>[1511, 300]</td><td>0</td><td>3.3933e-6</td><td>7.58202e-7</td><td>1.54011e-8</td><td>2.35168e-11</td><td>2.6559e-15</td></tr><tr><th>27</th><td>[261, 500]</td><td>0</td><td>0.0128459</td><td>0.0350468</td><td>0.0471163</td><td>0.0737188</td><td>0.0985059</td></tr><tr><th>28</th><td>[1071, 450]</td><td>1</td><td>0.0016161</td><td>0.00805005</td><td>0.00981623</td><td>0.0127817</td><td>0.0209876</td></tr><tr><th>29</th><td>[7040, 300]</td><td>0</td><td>0.0193813</td><td>0.0363146</td><td>0.0626254</td><td>0.0815899</td><td>0.0681219</td></tr><tr><th>30</th><td>[1501, 350]</td><td>1</td><td>0.00354222</td><td>0.00528918</td><td>0.00220595</td><td>0.000102948</td><td>3.69929e-7</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& sims & labels & feature\\_1 & feature\\_2 & feature\\_3 & feature\\_4 & feature\\_5 & \\\\\n",
       "\t\\hline\n",
       "\t& Array… & Any & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & [951, 500] & 0 & 0.011055 & 0.0230288 & 0.0252146 & 0.0153139 & 0.0127972 & $\\dots$ \\\\\n",
       "\t2 & [651, 450] & 1 & 0.0145121 & 0.0130357 & 0.0150536 & 0.0291809 & 0.0265747 & $\\dots$ \\\\\n",
       "\t3 & [901, 250] & 0 & 1.98983e-9 & 7.00509e-7 & 0.00024704 & 0.00665223 & 0.0187105 & $\\dots$ \\\\\n",
       "\t4 & [1371, 250] & 1 & 5.55306e-24 & 2.45581e-23 & 2.4084e-23 & 5.05982e-24 & 9.5356e-26 & $\\dots$ \\\\\n",
       "\t5 & [1151, 350] & 1 & 0.00296121 & 0.00619825 & 0.0107698 & 0.00703784 & 0.000701231 & $\\dots$ \\\\\n",
       "\t6 & [821, 400] & 1 & 0.00421397 & 0.0187837 & 0.0296966 & 0.0199009 & 0.00742934 & $\\dots$ \\\\\n",
       "\t7 & [6410, 450] & 1 & 0.00125018 & 0.00613746 & 0.0113962 & 0.0179503 & 0.0253942 & $\\dots$ \\\\\n",
       "\t8 & [1151, 450] & 1 & 0.00616752 & 0.0121388 & 0.016132 & 0.0236991 & 0.0178399 & $\\dots$ \\\\\n",
       "\t9 & [771, 450] & 0 & 0.00141156 & 0.00124019 & 0.00550951 & 0.013438 & 0.0220592 & $\\dots$ \\\\\n",
       "\t10 & [451, 500] & 0 & 0.0101826 & 0.0232314 & 0.0313183 & 0.0272385 & 0.0300795 & $\\dots$ \\\\\n",
       "\t11 & [461, 500] & 0 & 0.0171828 & 0.0337653 & 0.0553214 & 0.0778543 & 0.0736219 & $\\dots$ \\\\\n",
       "\t12 & [6730, 250] & 0 & 3.73077e-6 & 0.000253219 & 0.00148327 & 0.00168478 & 0.000569692 & $\\dots$ \\\\\n",
       "\t13 & [1351, 250] & 0 & 8.77536e-48 & 5.89834e-47 & 7.19013e-47 & 2.22669e-47 & 6.8542e-49 & $\\dots$ \\\\\n",
       "\t14 & [1381, 350] & 1 & 0.00389989 & 0.00577678 & 0.0025902 & 0.000141016 & 5.97338e-7 & $\\dots$ \\\\\n",
       "\t15 & [51, 500] & 0 & 0.0278803 & 0.0619403 & 0.0836656 & 0.0915658 & 0.0577899 & $\\dots$ \\\\\n",
       "\t16 & [6190, 400] & 0 & 0.00809457 & 0.0244316 & 0.0366216 & 0.0323021 & 0.0308711 & $\\dots$ \\\\\n",
       "\t17 & [1121, 350] & 1 & 0.00639722 & 0.0165158 & 0.0313132 & 0.0329414 & 0.029612 & $\\dots$ \\\\\n",
       "\t18 & [1191, 500] & 1 & 0.012989 & 0.0236959 & 0.0249193 & 0.0202414 & 0.019648 & $\\dots$ \\\\\n",
       "\t19 & [941, 350] & 1 & 0.000827498 & 0.000323136 & 0.000655285 & 0.011354 & 0.0455154 & $\\dots$ \\\\\n",
       "\t20 & [6580, 300] & 0 & 0.000696665 & 0.00130676 & 0.00297553 & 0.00814676 & 0.0076814 & $\\dots$ \\\\\n",
       "\t21 & [1191, 300] & 0 & 4.78119e-9 & 9.15957e-7 & 1.37427e-5 & 2.61787e-5 & 1.43727e-5 & $\\dots$ \\\\\n",
       "\t22 & [421, 250] & 0 & 0.000429851 & 0.000964426 & 0.00346012 & 0.00414652 & 0.00182862 & $\\dots$ \\\\\n",
       "\t23 & [611, 500] & 0 & 0.00637551 & 0.0100621 & 0.00819 & 0.00440917 & 0.0203919 & $\\dots$ \\\\\n",
       "\t24 & [621, 500] & 1 & 0.0086813 & 0.0194345 & 0.0254169 & 0.0439718 & 0.0548299 & $\\dots$ \\\\\n",
       "\t25 & [921, 400] & 1 & 0.00369839 & 0.00704631 & 0.0116764 & 0.00892959 & 0.00133876 & $\\dots$ \\\\\n",
       "\t26 & [1511, 300] & 0 & 3.3933e-6 & 7.58202e-7 & 1.54011e-8 & 2.35168e-11 & 2.6559e-15 & $\\dots$ \\\\\n",
       "\t27 & [261, 500] & 0 & 0.0128459 & 0.0350468 & 0.0471163 & 0.0737188 & 0.0985059 & $\\dots$ \\\\\n",
       "\t28 & [1071, 450] & 1 & 0.0016161 & 0.00805005 & 0.00981623 & 0.0127817 & 0.0209876 & $\\dots$ \\\\\n",
       "\t29 & [7040, 300] & 0 & 0.0193813 & 0.0363146 & 0.0626254 & 0.0815899 & 0.0681219 & $\\dots$ \\\\\n",
       "\t30 & [1501, 350] & 1 & 0.00354222 & 0.00528918 & 0.00220595 & 0.000102948 & 3.69929e-7 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m541×227 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m sims        \u001b[0m\u001b[1m labels \u001b[0m\u001b[1m feature_1   \u001b[0m\u001b[1m feature_2   \u001b[0m\u001b[1m feature_3   \u001b[0m\u001b[1m feature_4  \u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Array…      \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64    \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ [951, 500]   0       0.011055     0.0230288    0.0252146    0.0153139   ⋯\n",
       "   2 │ [651, 450]   1       0.0145121    0.0130357    0.0150536    0.0291809\n",
       "   3 │ [901, 250]   0       1.98983e-9   7.00509e-7   0.00024704   0.00665223\n",
       "   4 │ [1371, 250]  1       5.55306e-24  2.45581e-23  2.4084e-23   5.05982e-24\n",
       "   5 │ [1151, 350]  1       0.00296121   0.00619825   0.0107698    0.00703784  ⋯\n",
       "   6 │ [821, 400]   1       0.00421397   0.0187837    0.0296966    0.0199009\n",
       "   7 │ [6410, 450]  1       0.00125018   0.00613746   0.0113962    0.0179503\n",
       "   8 │ [1151, 450]  1       0.00616752   0.0121388    0.016132     0.0236991\n",
       "   9 │ [771, 450]   0       0.00141156   0.00124019   0.00550951   0.013438    ⋯\n",
       "  10 │ [451, 500]   0       0.0101826    0.0232314    0.0313183    0.0272385\n",
       "  11 │ [461, 500]   0       0.0171828    0.0337653    0.0553214    0.0778543\n",
       "  ⋮  │      ⋮         ⋮          ⋮            ⋮            ⋮            ⋮      ⋱\n",
       " 532 │ [1221, 500]  1       0.0114714    0.0235896    0.020648     0.00796405\n",
       " 533 │ [1251, 500]  1       0.00973609   0.014096     0.0180637    0.0261011   ⋯\n",
       " 534 │ [1521, 450]  1       0.00292622   0.0165902    0.0213107    0.00795415\n",
       " 535 │ [6050, 400]  0       5.7355e-20   1.32109e-16  3.14894e-13  5.75925e-11\n",
       " 536 │ [1561, 500]  1       0.00326449   0.00377417   0.00459155   0.0157308\n",
       " 537 │ [261, 250]   0       6.88251e-8   1.6576e-6    0.000209805  0.00247813  ⋯\n",
       " 538 │ [1381, 500]  1       0.00983087   0.0110934    0.00314745   9.56859e-5\n",
       " 539 │ [821, 500]   1       0.0127138    0.0298363    0.0230174    0.00856873\n",
       " 540 │ [661, 450]   1       0.00841426   0.0289745    0.0547058    0.0542703\n",
       " 541 │ [221, 350]   0       0.0031417    0.00615437   0.0151543    0.0214904   ⋯\n",
       "\u001b[36m                                                221 columns and 520 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random undersampling \n",
    "\n",
    "class_0 = countmap(df.labels)[0]\n",
    "class_1 = countmap(df.labels)[1]\n",
    "\n",
    "Random.seed!(1);\n",
    "df=df[shuffle(1:nrow(df)),:];   \n",
    "\n",
    "if class_0 > class_1 \n",
    "    # randomly undersample class 0\n",
    "\n",
    "    prob_to_delete = (class_0-class_1)/(class_0)\n",
    "    rows_to_delete = []\n",
    "    for row in 1:length(df.labels)\n",
    "        if df[row,:labels] == 0\n",
    "            if rand() < prob_to_delete\n",
    "                append!(rows_to_delete,row)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    delete!(df,rows_to_delete)\n",
    "elseif class_1 > class_0 \n",
    "    # randomly undersample class 1\n",
    "\n",
    "    prob_to_delete = (class_1-class_0)/(class_1)\n",
    "    rows_to_delete = []\n",
    "    for row in 1:length(df.labels)\n",
    "        if df[row,:labels] == 1\n",
    "            if rand() < prob_to_delete\n",
    "                append!(rows_to_delete,row)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    delete!(df,rows_to_delete)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Int64} with 2 entries:\n",
       "  0 => 272\n",
       "  1 => 269"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countmap(df.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample training, test and validation sets\n",
    "\n",
    "Random.seed!(1);\n",
    "df=df[shuffle(1:nrow(df)),:];   \n",
    "\n",
    "X = Matrix(df[:,3:end]);    \n",
    "y = df.labels;  \n",
    "\n",
    "train_ratio = 0.6\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,test_size=1-train_ratio); # train-test split\n",
    "Xval, Xtest, yval, ytest = train_test_split(Xtest,ytest,test_size= (test_ratio)/(test_ratio+validation_ratio)); # test-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter optimisation on training and validation set \n",
    "# could add search over more parameters too\n",
    "gammas = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "costs = gammas\n",
    "Cs = [] \n",
    "Gs = []\n",
    "max = 0\n",
    "for i=1:1:7\n",
    "    G = gammas[i]\n",
    "    for j=1:1:7\n",
    "        C = costs[j]\n",
    "        model = svmtrain(Xtrain', ytrain ; gamma=G , cost=C)\n",
    "        ypredict, decision_values = svmpredict(model, Xval');\n",
    "        acc = mean(ypredict .== yval) * 100;\n",
    "        if acc > max \n",
    "            #println(\"current max: \",acc )\n",
    "            max = acc\n",
    "            append!(Cs,C)\n",
    "            append!(Gs,G)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 1.0\n",
      "Gamma: 100.0\n"
     ]
    }
   ],
   "source": [
    "println(\"Cost: \", Cs[end])\n",
    "println(\"Gamma: \", Gs[end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 78.89908256880734\n"
     ]
    }
   ],
   "source": [
    "# report final accuracy on test set\n",
    "\n",
    "model = svmtrain(Xtrain', ytrain ; gamma=Gs[end] , cost=Cs[end])\n",
    "\n",
    "ypredict, decision_values = svmpredict(model, Xtest');\n",
    "acc = mean(ypredict .== ytest) * 100;\n",
    "println(\"accuracy: \", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09c6cbd744a3e802c1b5f435d264ee7d2f5cdf10497892df26b386a33f32af57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
